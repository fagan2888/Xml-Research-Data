<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>NSF-CONACyT: Binational Collaborative Development of Spoken Language Technology in Latin American Spanish</AwardTitle>
    <AwardEffectiveDate>10/01/2001</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2003</AwardExpirationDate>
    <AwardAmount>93570</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Mary P. Harper</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>CONACyT: Binational Collaborative Development of Spoken Language&lt;br/&gt;Technology in Latin American Spanish&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This is a standard award. As the use of handheld computing devices becomes more widespread it will be increasingly necessary for these devices to support speech input and output that can maintain robust performance under all conditions. In this project the CMU Robust Speech Group will develop a series of complementary algorithms that will substantially improve the accuracy of automatic speech recognition systems in the presence of difficult acoustical environments including high levels of noise, sources of interference with time-varying characteristics (such as competing speech sources and background music), and a variety of transient noise sources encountered in office, highway, and industrial settings. The research includes three complementary components: the development of "synergistic" sets of features that when used in combination will provide better recognition accuracy than can be obtained by any single feature set in isolation; development of a series of new procedures that produce the best combination of information from multiple parallel recognizers; and development of improved methods to achieve robust speech recognition by the explicit identification and reconstruction of features in time-frequency displays of speech that are "missing" by virtue of being damaged by noise or other types of interference. The PI will transfer the technology developed in the course of this project to industry and to the general public by releasing the code of successful algorithms in Open Source form.</AbstractNarration>
    <MinAmdLetterDate>09/18/2001</MinAmdLetterDate>
    <MaxAmdLetterDate>09/18/2001</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0116545</AwardID>
    <Investigator>
      <FirstName>Richard</FirstName>
      <LastName>Stern</LastName>
      <EmailAddress>rms@cs.cmu.edu</EmailAddress>
      <StartDate>09/18/2001</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0104000</Code>
      <Name>Information Systems</Name>
    </FoaInformation>
  </Award>
</rootTag>
