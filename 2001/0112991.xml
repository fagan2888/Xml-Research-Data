<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>ITR/SY: A Neuromorphic Vision System for Every-Citizen Interfaces</AwardTitle>
    <AwardEffectiveDate>08/15/2001</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2005</AwardExpirationDate>
    <AwardAmount>450000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>C.S. George Lee</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project aims to extend an existing simple saliency-based visual attention system to animated color video sequences so as to enable it to cue the object recognition module towards interesting locations in live video streams, and simultaneously to extend an existing model for object recognition to on-line adaptability through top-down signals and task- and object-dependent learning of features. The PIs will then integrate these attention and recognition models, by developing feedforward and feedback interactions between localization of regions of interest and object recognition in those regions. This will require substantial elaboration of both models, as well as specific work on their integration. The result will be a complete model of object localization and recognition in primates, with direct applicability to computer vision challenges. The PIs will next implement and deploy the combined model on a cluster of CPUs linked by very fast interconnect (just installed at USC) to allow for real-time processing, and will demonstrate its utility in a prototype video-conferencing application in which the on-line adaptive attentional component of the integrated system will quickly locate regions in the monitored environment where something interesting is happening (e.g., a user raising her hand in a conference room). The recognition part of the system will then be trained and refined on-line to recognize relatively simple hand signs (e.g., a finger pointing up, meaning that the user wishes to become the center of interest in a video-conference). This work will demonstrate two points: that a biologically-inspired approach to traditionally hard computer vision problems can yield unusually robust and versatile vision systems (which work with color video streams and quickly adapt to various environmental conditions, users, and tasks); and that computational neuroscience models of vision can be extended to yield real, useful and widely applicable computer vision systems, and are not restricted to testing neuroscience hypotheses under simple laboratory stimuli.</AbstractNarration>
    <MinAmdLetterDate>08/17/2001</MinAmdLetterDate>
    <MaxAmdLetterDate>08/17/2001</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0112991</AwardID>
    <Investigator>
      <FirstName>Laurent</FirstName>
      <LastName>Itti</LastName>
      <EmailAddress>itti@pollux.usc.edu</EmailAddress>
      <StartDate>08/17/2001</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Tomaso</FirstName>
      <LastName>Poggio</LastName>
      <EmailAddress>tp@ai.mit.edu</EmailAddress>
      <StartDate>08/17/2001</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Christof</FirstName>
      <LastName>Koch</LastName>
      <EmailAddress>ChristofK@alleninstitute.org</EmailAddress>
      <StartDate>08/17/2001</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>California Institute of Technology</Name>
      <CityName>PASADENA</CityName>
      <ZipCode>911250600</ZipCode>
      <PhoneNumber>6263956219</PhoneNumber>
      <StreetAddress>1200 E California Blvd</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0104000</Code>
      <Name>Information Systems</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>1686</Code>
      <Text>ITR SMALL GRANTS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1654</Code>
      <Text>HUMAN COMPUTER INTERFACE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9216</Code>
      <Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
