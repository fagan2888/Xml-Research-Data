<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Processing of Temporally-Coded Auditory Representations for Sound Separation and Localization</AwardTitle>
    <AwardEffectiveDate>01/15/2002</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2004</AwardExpirationDate>
    <AwardAmount>156945</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Mitra Basu</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>EIA-0130793 Ramdas Kumaresan University of Rhode Island Collaborative Research: Processing of Temporally-Coded Auditory Representations for Sound Separation and Localization&lt;br/&gt;&lt;br/&gt;The proposed work investigates the use of two temporally-coded representations and temporal processing strategies for the separation of auditory objects. Two temporal representations and temporal processing strategies for the separation of auditory objects will be used. Two temporal representations of input signals will be used. These are 1) phase-locked spike train responses in a simulated auditory nerve array (Auditory Temporal Images), and 2) an auditory-inspired signal representation based on adaptive demodulation (Adaptive Demodulation and Real-Zero Conversion) that converts bandpass signals into timings of certain zero crossings.&lt;br/&gt;&lt;br/&gt;Temporal coding through phase locking is a very general strategy for representing sensory information through the relative timings of spikes. Temporal coding is found in many sensory systems: audition (periodicity and frequency discrimination, localization, echolocation), mechanoception (flutter-vibration, localization, movement), electroception (localization), and vision (fly motion detection). The unsurpassed capabilities of biological auditory systems to separate, analyze, and recognize multiple sounds may be due to the early use of temporal codes and computations, but thus far there have been relatively few attempts to effectively exploit these time domain strategies in artificial signal processing contexts. This collaborative project will combine understanding of the neural substrates of auditory perception (Cariani) with mathematical insights and expertise in signal processing (Kumaresan) to develop new biologically inspired time-domain approaches to auditory scene analysis.</AbstractNarration>
    <MinAmdLetterDate>01/11/2002</MinAmdLetterDate>
    <MaxAmdLetterDate>11/20/2002</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0130793</AwardID>
    <Investigator>
      <FirstName>Ramdas</FirstName>
      <LastName>Kumaresan</LastName>
      <EmailAddress>kumar@ele.uri.edu</EmailAddress>
      <StartDate>01/11/2002</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Rhode Island</Name>
      <CityName>KINGSTON</CityName>
      <ZipCode>028811967</ZipCode>
      <PhoneNumber>4018742635</PhoneNumber>
      <StreetAddress>RESEARCH OFFICE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Rhode Island</StateName>
      <StateCode>RI</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
  </Award>
</rootTag>
